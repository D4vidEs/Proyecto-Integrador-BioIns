# DeepACO / ACO ‚Äî Reproducci√≥n en TSP (20/100/500)

Reproducci√≥n y an√°lisis de **DeepACO** y **ACO** sobre instancias del **Traveling Salesman Problem (TSP)**.  
Este repositorio acompa√±a el reporte t√©cnico: incluye instrucciones de instalaci√≥n, gu√≠a de ejecuci√≥n, organizaci√≥n de archivos y notas de reproducibilidad.

> Paper base: *DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization* (NeurIPS 2023).  
> C√≥digo base: repositorio oficial de DeepACO (modificaciones m√≠nimas documentadas en el reporte).

---

## üìÅ 

```
.
‚îú‚îÄ tsp/
‚îÇ  ‚îú‚îÄ aco.py
‚îÇ  ‚îú‚îÄ net.py
‚îÇ  ‚îú‚îÄ utils.py
‚îÇ  ‚îî‚îÄ __init__.py
‚îÇ  ‚îî‚îÄ test.ipynb
‚îÇ  ‚îî‚îÄ train.ipynb
‚îú‚îÄ README.md
```
---

##  Requisitos

- **Python 3.8.20**
- **PyTorch** (CPU o CUDA)
- **PyTorch Geometric (PyG)**
- NumPy, Matplotlib
- d2l` para animaciones/monitoreo


> **GPU (CUDA):** instala la build de Torch compatible con tu versi√≥n de CUDA y, luego, PyG seg√∫n su gu√≠a oficial.

---

## C√≥mo correr los experimentos

### 1) aco.py
- En este archivo se retiene el algoritmo de ACO con sus parametros.
- Ejecuta

### 2) net.py
- Este tiene la red neuronal. 
- Ejecutar.

### 3) train.ipynb
- Abre `train.ipynb`.
- Selecciona `device="cpu"` (o `"cuda"` si tienes GPU compatible).
- Ejecuta las celdas de **entrenamiento** de la red sobre el algoritmo.

### 4) test.ipynb
- Ejecuta los bloques, aqui es donde cambias parametros como nodos o cantidad de hormigas para el problema.
---

## Figuras y tablas del informe

Este repositorio almacena los recursos usados en el reporte:

- **Reproducibilidad por tama√±o** (TSP20, TSP100, TSP500) y sus respectivos resultados.
```

> En el informe LaTeX se us√≥ redondeo a **5 decimales**.

---

##  Reproducibilidad

- **Presupuesto**: compara por el mismo **n√∫mero de evaluaciones T** (1,10,20,30,40,50,100).
- **Dispositivo**: CPU por defecto; documenta si usas GPU (modelos/tiempos pueden cambiar).
- **Versionado**: registra versiones de librer√≠as y comandos exactos ejecutados.

---

## Resultados de referencia (los usados en el informe)

**TSP20 (DeepACO, CPU)**  
- Repo: 3.92767 (T=1) ‚Üí 3.85062 (T=100)  
- Modificado: id√©ntico por T (a 5 decimales); tiempo total ‚âà **886.46 s** vs **915.16 s** (‚àí3.1%)

**TSP100 (ACO, CPU)**  
- Repo: 13.63478 (T=1) ‚Üí 9.55358 (T=100)  
- Modificado: 13.65005 ‚Üí 9.56497 (**Œî** ‚â§ 0.12%); tiempo total ‚âà **2759.84 s** vs **2697.08 s** (+2.33%)

> Pueden variar levemente por hardware/semillas.

---

##  Problemas comunes

- **PyTorch/PyG incompatibles**: instala primero Torch (CPU o CUDA), luego PyG compatible.
- **Pesos preentrenados** (si aplican): usa `map_location="cpu"` si corres sin GPU.
---

## üôè Agradecimientos

A los autores de DeepACO por el repositorio original y a la comunidad de PyTorch/PyG por sus herramientas.

Este repositorio es una reproducci√≥n del trabajo original de:

- Ye, Haoran; Wang, Jiarui; Cao, Zhiguang; Liang, Helan; Li, Yong.  
  *DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization (NeurIPS 2023).*  

Repositorio original: <https://github.com/henry-yeh/DeepACO.git>  
Todo el cr√©dito por la idea y el c√≥digo base es de sus autores; este repositorio solo documenta nuestra reproducci√≥n y comparaciones.
